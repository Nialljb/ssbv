{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Subject Brain Volumetric Analysis \n",
    "### Beta run at local Jupyter notebook that can submit jobs remotely to the HPC\n",
    "*nbourke@imperial.ac.uk March 2022* \n",
    "\n",
    "* Set up as a Git repo with branch on HPC, \n",
    "* Jupyter lab spawned on local machine that has HPC mounted with access to file system. \n",
    "\n",
    "## Overview\n",
    "This notebook takes a set of scans and tells you what the volumes of grey matter, white matter and CSF are. It also lets you run a voxelwise comparison (voxel based morphometry) between the two groups (patients versus controls) to see whether the volume at each voxel is significantly different. Eg. Do patients have smaller brains (ie are they more atrophic) than controls?\n",
    "\n",
    "The notebook uses SPM12 (UCL) to do most of the heavy lifting, and then FSL for the stats. You might find the SPM manual useful: https://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf.\n",
    "\n",
    "Matlab dependencies by Neil Graham and Greg Scott\n",
    "\n",
    "### TO DO:\n",
    "* Take template creation out of this notebook \n",
    "    - generate templates for age bins\n",
    "    - match single subject to appropriate template and translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "You will need: \n",
    "\n",
    "-Data stored in BIDS format  \n",
    "\n",
    "* hpcwrapmatlab.sh\n",
    "* hpcrunarrayjob.sh\n",
    "* segment_t1.m\n",
    "* make_template.m\n",
    "* generate_flowfields.m\n",
    "* move_to_mni.m\n",
    "\n",
    "**All of these scripts should be in the dependencies folder now**\n",
    "\n",
    "### Development notes:\n",
    "\n",
    "- Auth keys are disabled on cluster - requires passing shh details \n",
    "- Requires mounted volume (mac = osfuse)\n",
    "- Need to set paths from both local/remote file systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of volumes from T1 sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define some paths and get FSL loaded etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "##### python cell\n",
    "    1. enter project ID\n",
    "    2. If this project doesn't exist in in the temporary space, create it\n",
    "    3. Set importnat paths that will be used\n",
    "    4. Make a setup script to save bash variables in\n",
    "    \n",
    "    \n",
    "* Have cluster mounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "# Define project name\n",
    "project = \"ssbv\" \n",
    "\n",
    "# Set project dir in ephermeral \n",
    "directory = (home + \"/hpc/eph/\" + project + \"/data/\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "workingDir = (home + \"/hpc/eph/\" + project + \"/\")\n",
    "wd = (home + \"/eph/\" + project + \"/\")\n",
    "setup = (workingDir + \"/setup.sh\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bash cell\n",
    "This cell adds bash variables you want to save to a setup script, which can then be called in future python cells. \n",
    "\n",
    "1. Add project name\n",
    "2. Add paths of interest\n",
    "3. Define modules that will be needed\n",
    "\n",
    "### Symbolic links can be created to specific shared folders with appropriate permissions, but not top level project directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/nbourke/hpc/eph/ssbv//setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile $setup\n",
    "\n",
    "$(: Project label) \n",
    "project=\"ssbv\"\n",
    "\n",
    "$(: dependencies)\n",
    "export repo=pwd\n",
    "export dep=${repo}/lib\n",
    "export workingDir=~/hpc/eph/${project}\n",
    "\n",
    "\n",
    "wd=/rds/general/user/nbourke/ephemeral/${project}\n",
    "# imData is a symbolic link to shared directory\n",
    "imData=~/hpc/imData\n",
    "raw=${imData}/raw\n",
    "\n",
    "source ~/.activate_imperial_rcs_login\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nbourke/hpc/eph/ssbv\n",
      "/Users/nbourke/hpc/repos/ssbv\n",
      "/tmp/ask\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "pwd\n",
    "\n",
    "echo ${ask}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data\n",
    "\n",
    "Copy data in BIDS format from source directory into a temporary working directory\n",
    "\n",
    "#### POPPY scans have not copied across - Not in sourcedata BIDS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "# ----------------\n",
    "\n",
    "\n",
    "for sub in `cat cifid.txt`; \n",
    "    do\n",
    "    for ses in `ls ${imData}/sourcedata/sub-${sub}`;\n",
    "        do\n",
    "        #echo ${ses}\n",
    "        mkdir -p ${workingDir}/data/sub-${sub}/${ses}/anat/T1w/\n",
    "        tmp=`ls ${imData}/sourcedata/sub-${sub}/${ses}/anat/T1w/*T1w*`\n",
    "        echo $tmp\n",
    "        cp ${tmp} ${workingDir}/data/sub-${sub}/${ses}/anat/T1w/\n",
    "        gunzip ${workingDir}/data/sub-${sub}/${ses}/anat/T1w/*\n",
    "    done        \n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dry run complete, 159 unique individuals pulled across  \n",
    "- Data validation is required to check for new/missed participants not copied and to control for individuals with multiple scanning sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of T1 scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "# module load fsl\n",
    "#----------------------------\n",
    "\n",
    "# setup log dir\n",
    "if [ ! -d ${workingDir}/commandLogs/ ]; then\n",
    "    echo \"Making log dir!\"\n",
    "    mkdir ${workingDir}/commandLogs/\n",
    "fi\n",
    "#\n",
    "\n",
    "# Make a list of all T1 scans\n",
    "echo -n \"\" > ./tmp/t1_list.txt\n",
    "for s in `ls -d ${workingDir}/data/*`;\n",
    "    do\n",
    "    subj=`basename ${s}`\n",
    "    for ses in `ls ${workingDir}/data/${subj}`; \n",
    "        do \n",
    "        echo \"${wd}\"/data/${subj}/${ses}/anat/T1w/${subj}_${ses}_T1w.nii >> ./tmp/t1_list.txt\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Run segmentation jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "# module load fsl\n",
    "#----------------------------\n",
    "dep=/rds/general/project/c3nl_shared/live/dependencies\n",
    "\n",
    "# Segment T1 data\n",
    "echo -n \"\" > ./tmp/segmentationJobs.txt\n",
    "job=./tmp/segmentationJobs.txt\n",
    "#cjob=${wd}/commandLogs/segmentationJobs.txt\n",
    "\n",
    "for subject in `cat ./tmp/t1_list.txt`\n",
    "    do\n",
    "    echo \"${dep}/hpcwrapmatlab.sh \\\"maxNumCompThreads(3); segment_t1('${subject}');\\\"\" >> ${job}  \n",
    "done;\n",
    "\n",
    "    # Run job\n",
    "    ~/hpc/repos/ssbv/lib/localSubmit ${job} 01:00:00 3 6Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"; head ${job}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: check on your job progress\n",
    "- wont work locally, need to be on RCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After the job has completed look at the output:\n",
    "\n",
    "Four each subject you should have the following files:\n",
    "* subject....nii - this is the original untouched nifti - we could later delete it from here as it is stored in the sourcedata folder, in order to save space \n",
    "* c1 ....   - this is the grey matter segmented output\n",
    "* c2 ....   - this is the white matter segmented output\n",
    "* c3 ....   - this is the CSF segmented output\n",
    "* rc1 ... rc2  etc.. - this is a rigidly aligned GM segmented output (useful for later when we want to move files to 'standard space' such as MNI)\n",
    "* seg8 - has details of the segmentation to save SPM time if the software needs to reference the files later on\n",
    "\n",
    "And most importantly:\n",
    "* ...... vols.txt - this has your tissue volumes in it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vital step: Have a look at your scans to make sure the segmentation has worked properly in each case\n",
    "We can even generate some commands for you to use in the terminal with FSL.\n",
    "\n",
    "These are designed so it will be as painless as possible. Load up the terminal, connect to the HPC, make sure you do module load fsl\n",
    "\n",
    "1. Copy this cell into terminal to run all subjects (quit by pressing ctrl+c in terminal)\n",
    "2. Run this cell to get commands to copy into terminal to run one at a time\n",
    "\n",
    "*You want to ensure that the wm and gm are separated nicely and in a way which you think is appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fn = dir('/rds/general/user/nbourke/ephemeral/fa/*.gz');\n",
    "\n",
    "# % Now we want to view as a movie for QA purposes. \n",
    "# figure;ax = gca;\n",
    "# % use the following to force the Current figure handle to appear outside the live script\n",
    "# set(gcf,'Visible','on')\n",
    "# for ii=1:numel(fn)\n",
    "#     plotNifti([fn(ii).folder,filesep,fn(ii).name],ax);\n",
    "#     drawnow % will tell Matlab to create animation\n",
    "#     pause(0.2) % how long to pause between loading the next image\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can bundle up all of the vols.txt files into a big CSV for convenience, and put this in your notebook folder (within a subfolder called volumetric_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "#------------------\n",
    "\n",
    "if [ -d ${workingDir}/volumetric_results ]   \n",
    "    then\n",
    "    echo \"results folder ready\";\n",
    "    else\n",
    "    mkdir -p ${workingDir}/volumetric_results\n",
    "    echo \"results folder made\";\n",
    "fi\n",
    "   \n",
    "    echo \"subject,gm_vol,wm_vol,csf_vol\" > ${workingDir}/volumetric_results/volumes.csv \n",
    "    for subject in `ls ${workingDir}/data/`\n",
    "        do\n",
    "        for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "            do \n",
    "            volsfile=${workingDir}/data/$subject/${ses}/anat/T1w/*_vols.txt       \n",
    "            if [ -f ${volsfile} ]\n",
    "               then\n",
    "               echo -n \"${ses}\" >> ${workingDir}/volumetric_results/volumes.csv;\n",
    "               tail -n 1 ${volsfile} >> ${workingDir}/volumetric_results/volumes.csv;\n",
    "            fi\n",
    "        done\n",
    "    done;\n",
    "    \n",
    "echo \"done\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could download these CSVs into the analysis package of your choice and do some comparisons using the summary measures.\n",
    "\n",
    "Eg. t-test comparing the GM volume in patients versus controls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelwise statistics \n",
    "### (and steps to get the images in standard space to facilitate this)\n",
    "In order to do comparisons on the shapes of different brains they need to be moved into 'standard space' such as MNI. SPM can do this for us using 'DARTEL', an approach which preserves volume information on moving.\n",
    "\n",
    "Then we can use FSL randomise to do voxelwise comparisons between groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. First make a 'study-specific' template\n",
    "This is an average image of your subjects. Rather than going straight to standard space like MNI, it's better to go via a template. You could use all your subjects for this, or a selection of them. Ideally it should be 50% patients 50% controls.  Run the next cell to make a file listing which subjects to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file subjects_for_volumetric_template.txt\n",
    "sub-control001\n",
    "sub-control002\n",
    "sub-control003\n",
    "sub-patient001\n",
    "sub-patient002\n",
    "sub-patient003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "#------------------\n",
    "\n",
    "   \n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "        volsfile=${workingDir}/data/$subject/${ses}/anat/T1w/*_vols.txt       \n",
    "        if [ -f ${volsfile} ]\n",
    "           then\n",
    "        \n",
    "           echo \"${subject}\" >> ${workingDir}/existingT1.txt;\n",
    "        fi\n",
    "    done\n",
    "done;\n",
    "    \n",
    "sort existingT1.txt | uniq -u >> T1_list.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make the template.\n",
    "\n",
    "This can take a while so you can increase the number from 3 hours to something more generous if you've got lots of subjects.\n",
    "\n",
    "It will not work if there are too many participants (limit to no more than 100 max)\n",
    "\n",
    "\\* Make a template for each age bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s \"$setup\"\n",
    "# export setup=$1;\n",
    "# source ${setup}\n",
    "# echo ${workingDir}\n",
    "# #------------------\n",
    "\n",
    "# # module load fsl\n",
    "# #----------------------------\n",
    "# dep=/rds/general/project/c3nl_shared/live/dependencies\n",
    "\n",
    "# # this uses the RC rigidly aligned files from the segmentation output : if you want to have a look at them use this in bash  \n",
    "# echo -n \"\" > ./tmp/templateJob.txt\n",
    "# job=./tmp/templateJob.txt\n",
    "\n",
    "#     files=\"\"\n",
    "  \n",
    "# echo \"\" > ./tmp/subj.txt   \n",
    "\n",
    "# for subject in `ls ${workingDir}/data/`\n",
    "#     do\n",
    "#     for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "#         do \n",
    "#          echo ${subject} >> ./tmp/subj.txt   \n",
    "#         trc1=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc1*T1w.nii`;\n",
    "#         trc2=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc2*T1w.nii`;\n",
    "#         trc3=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc3*T1w.nii`;\n",
    "#         rc1=${wd}/data/${subject}/${ses}/anat/T1w/${trc1}\n",
    "#         rc2=${wd}/data/${subject}/${ses}/anat/T1w/${trc2}\n",
    "#         rc3=${wd}/data/${subject}/${ses}/anat/T1w/${trc3}\n",
    "        \n",
    "#         if [ -z \"${files}\" ]; then\n",
    "#          files=\"'${rc1}','${rc2}','${rc3}'\";\n",
    "#         else\n",
    "#          files=\"${files},'${rc1}','${rc2}','${rc3}'\";\n",
    "#         fi\n",
    "#     done\n",
    "# done\n",
    "     \n",
    "#      echo \"${dep}/hpcwrapmatlab.sh \\\"maxNumCompThreads(3); make_template('Template', ${files});\\\"\" > ${job};\n",
    "              \n",
    "\n",
    "#     # Setup SSH connection (add to profile)\n",
    "\n",
    "#     # Run job\n",
    "#     ~/hpc/repos/ssbv/lib/localSubmit ${job} 71:00:00 3 8Gb\n",
    "#     echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"; head ${job}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st session for each subject\n",
    "* T1_list.txt is a list of unique ids that have existing T1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "#------------------\n",
    "\n",
    "# module load fsl\n",
    "#----------------------------\n",
    "dep=/rds/general/project/c3nl_shared/live/dependencies\n",
    "\n",
    "# this uses the RC rigidly aligned files from the segmentation output : if you want to have a look at them use this in bash  \n",
    "echo -n \"\" > ./tmp/templateJob.txt\n",
    "job=./tmp/templateJob.txt\n",
    "\n",
    "files=\"\"\n",
    "  \n",
    "for subject in `cat ${workingDir}/T1_list.txt`;\n",
    "    do\n",
    "    visit=`basename ${workingDir}/data/${subject}/*` #(*)\n",
    "    #echo \"${files[0]}\"\n",
    "    ses=\"${visit[0]}\"\n",
    "\n",
    "    trc1=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc1*T1w.nii`;\n",
    "    trc2=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc2*T1w.nii`;\n",
    "    trc3=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc3*T1w.nii`;\n",
    "    rc1=${wd}/data/${subject}/${ses}/anat/T1w/${trc1}\n",
    "    rc2=${wd}/data/${subject}/${ses}/anat/T1w/${trc2}\n",
    "    rc3=${wd}/data/${subject}/${ses}/anat/T1w/${trc3}\n",
    "    \n",
    "    if [ -z \"${files}\" ]; then\n",
    "     files=\"'${rc1}','${rc2}','${rc3}'\";\n",
    "    else\n",
    "     files=\"${files},'${rc1}','${rc2}','${rc3}'\";\n",
    "    fi\n",
    "done\n",
    "     \n",
    "     echo \"${dep}/hpcwrapmatlab.sh \\\"maxNumCompThreads(3); make_template('Template', ${files});\\\"\" > ${job};\n",
    "              \n",
    "\n",
    "    # Setup SSH connection (added to profile: ~/.activate_imperial_rcs_login)\n",
    "\n",
    "    # Run job\n",
    "    ~/hpc/repos/ssbv/lib/localSubmit ${job} 71:00:00 3 8Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"; head ${job} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the job is done, you need to move the completed template files to a nice new folder, as by default they are dumped into the **first** subject's folder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "#------------------\n",
    "\n",
    "# line=$(head -n 2 ./tmp/subj.txt) \n",
    "# echo $line\n",
    "\n",
    "#mkdir -p ${workingDir}/DARTEL_template/\n",
    "cp ${workingDir}/data/sub-CIF0354/ses-DREAM003_baseline_v1/anat/T1w/Template_* ${workingDir}/DARTEL_template/;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Make flowfields to the newly made group template for each subject's scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "#------------------\n",
    "\n",
    "dep=/rds/general/project/c3nl_shared/live/dependencies\n",
    "    \n",
    "template_basename=\"Template\"\n",
    "template=${wd}/DARTEL_template/${template_basename}\n",
    "\n",
    "unset files;\n",
    "echo \"\" > ./tmp/flowfields.txt\n",
    "job=./tmp/flowfields.txt\n",
    "\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "\n",
    "        files=\"\"\n",
    "    \n",
    "        trc1=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc1*T1w.nii`;\n",
    "        trc2=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc2*T1w.nii`;\n",
    "        trc3=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/rc3*T1w.nii`;\n",
    "        rc1=${wd}/data/${subject}/${ses}/anat/T1w/${trc1}\n",
    "        rc2=${wd}/data/${subject}/${ses}/anat/T1w/${trc2}\n",
    "        rc3=${wd}/data/${subject}/${ses}/anat/T1w/${trc3}\n",
    "        \n",
    "        files=\"'${rc1}','${rc2}','${rc3}'\";\n",
    "\n",
    "        if [ -f ${workingDir}/data/${subject}/${ses}/anat/T1w/$trc1 ];\n",
    "        then\n",
    "\n",
    "        echo \"${dep}/hpcwrapmatlab.sh \\\"generate_flowfields('${template}', ${files})\\\"\" >> ${job}; \n",
    "\n",
    "        else\n",
    "        echo \"No rc1 file for ${subject} at visit ${visit}\";\n",
    "        fi\n",
    "\n",
    "        unset files;\n",
    "    done\n",
    "done\n",
    "         \n",
    "    # Run job\n",
    "    ~/hpc/repos/ssbv/lib/localSubmit ${job} 48:00:00 3 6Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"; head ${job}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Use the flowfields to send the images to MNI space\n",
    "\n",
    "This uses smoothing with an 8mm gaussian kernel. This is reasonable...\n",
    "It uses the 'preserve volumes' option, whereby when a voxel is grown/expanded in the move to MNI, its value its reduced  (ie. the concentration of that voxel is modulated).\n",
    "\n",
    "If you need to change these settings edit the script move_to_mni.m and then re run your cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "#------------------\n",
    "   \n",
    "dep=/rds/general/project/c3nl_shared/live/dependencies\n",
    "    \n",
    "template_basename=\"Template\"\n",
    "template=${wd}/DARTEL_template/${template_basename}_6.nii\n",
    "\n",
    "\n",
    "unset files;\n",
    "echo \"\" > ./tmp/register2MNI.txt;\n",
    "job=./tmp/register2MNI.txt;\n",
    "\n",
    "\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "\n",
    "        files=\"\"\n",
    "\n",
    "        tu_rc1=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/u_rc1*_T1w.nii`;\n",
    "        tc1=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/c1*_T1w.nii`;\n",
    "        tc2=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/c2*_T1w.nii`;\n",
    "        tc3=`basename ${workingDir}/data/${subject}/${ses}/anat/T1w/c3*_T1w.nii`;\n",
    "        \n",
    "        u_rc1=${wd}/data/${subject}/${ses}/anat/T1w/${tu_rc1}\n",
    "        c1=${wd}/data/${subject}/${ses}/anat/T1w/${tc1}\n",
    "        c2=${wd}/data/${subject}/${ses}/anat/T1w/${tc2}\n",
    "        c3=${wd}/data/${subject}/${ses}/anat/T1w/${tc3}\n",
    "        \n",
    "        files=\"'${u_rc1}','${c1}','${c2}','${c3}'\";\n",
    "\n",
    "\n",
    "        if [ -f ${workingDir}/data/${subject}/${ses}/anat/T1w/$tu_rc1 ];\n",
    "        then\n",
    "        echo \"${dep}/hpcwrapmatlab.sh \\\"move_to_mni('${template}', ${files})\\\"\" >> ${job};\n",
    "        else\n",
    "        echo \"No flowfield for this person ${subject} and timepoint ${session}\";\n",
    "        fi\n",
    "\n",
    "        unset files;\n",
    "    done\n",
    "done\n",
    "         \n",
    "    # Run job\n",
    "    ~/hpc/repos/ssbv/lib/localSubmit ${job} 48:00:00 3 6Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"; head ${job}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "${fsl}\n",
    "#----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC CHECK: Have a look at your MNI space spatially normalised and smoothed Jacobian images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Some tract stats in fsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nbourke/hpc/eph/ssbv\n",
      "input is = ./tmp/smwc1statsJob.txt\n",
      "Walltime = 48:00:00\n",
      "Number of CPUs = 3\n",
      "Memory = 16Gb\n",
      "login is : ssh nbourke@login.hpc.ic.ac.uk\n",
      "jobs =        1\n",
      "WARNING: only one job submitted!\n",
      "Check this correct\n",
      "PBS file = \n",
      "/var/folders/kw/ttpm9tz913j6zqhngnlnfsg00000gn/T/tmp.nsBrQYPV\n",
      "Job submitted: Tue 29 Mar 2022 11:12:51 BST\n",
      "5378918.pbs\n",
      "\n",
      "***\n",
      "\n",
      "Submitted commands:\n",
      "module load fsl; fslmerge -t /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc1 `cat /rds/general/user/nbourke/ephemeral/ssbv/smwc1_list.txt`; fslmaths /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc1 -max 0 -Tmin -bin /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc1_mask -odt char; fslmaths /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc1 -mas /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc1_mask /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc1; fslmaths /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc1 -Tmean /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/mean_smwc1; fslmaths /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/mean_smwc1 -thr 0.5 -bin /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/mean_smwc1_mask \n",
      "input is = ./tmp/smwc2statsJob.txt\n",
      "Walltime = 48:00:00\n",
      "Number of CPUs = 3\n",
      "Memory = 16Gb\n",
      "login is : ssh nbourke@login.hpc.ic.ac.uk\n",
      "jobs =        1\n",
      "WARNING: only one job submitted!\n",
      "Check this correct\n",
      "PBS file = \n",
      "/var/folders/kw/ttpm9tz913j6zqhngnlnfsg00000gn/T/tmp.y7mfkvSQ\n",
      "Job submitted: Tue 29 Mar 2022 11:12:56 BST\n",
      "5378919.pbs\n",
      "\n",
      "***\n",
      "\n",
      "Submitted commands:\n",
      "module load fsl; fslmerge -t /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc2 `cat /rds/general/user/nbourke/ephemeral/ssbv/smwc2_list.txt`; fslmaths /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc2 -max 0 -Tmin -bin /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc2_mask -odt char; fslmaths /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc2 -mas /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc2_mask /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc2; fslmaths /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/all_smwc2 -Tmean /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/mean_smwc2; fslmaths /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/mean_smwc2 -thr 0.5 -bin /rds/general/user/nbourke/ephemeral/ssbv/volumetric_results/mean_smwc2_mask \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0092/ses-2013-10-28-13_10_28_visit1_SMH0076/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0092/ses-2015-10-27-POPPY_SMH0076/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0117/ses-2013-11-29-13_11_29_visit1_SMH0070/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0117/ses-2015-10-13-POPPY_SMH0070_MV2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0135/ses-2013-12-20-13_12_20_visit1_SMH0193/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0135/ses-2015-10-30-POPPY_SMH0193_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0148/ses-2014-01-21-14_01_21_visit1_SMH0228v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0148/ses-2015-11-11-POPPY_SMH0228_MV2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0150/ses-2014-01-28-14_01_28_visit1_SMH0213v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0150/ses-2015-11-03-POPPY_SMH0213_MV2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0157/ses-2014-02-03-14_02_03_visit1_SMH0206v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0157/ses-2015-11-30-POPPY_SMH_0206_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0202/ses-2014-03-07-14_03_07_visit1_SMH0299v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0202/ses-2015-12-08-POPPY_SMH_0299_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0203/ses-2014-03-07-14_03_07_visit1_SMH0286v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0203/ses-2015-12-08-SMH_0286_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0215/ses-2014-03-13-14_03_13_visit1_SMH0313v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0215/ses-2015-12-01-POPPY_SMH0313_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0217/ses-2014-03-14-14_03_14_visit1_SMH0323v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0217/ses-2015-12-08-POPPY_SMH0323_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0220/ses-2014-03-24-14_03_24_visit1_SMH0301v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0220/ses-2015-11-17-POPPY_SMH0301_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0225/ses-2014-03-27-14_03_27_visit1_SMH0334v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0225/ses-2015-09-14-SMH0334_MV2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0237/ses-2014-04-10-SMH0308_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0237/ses-2016-02-09-POPPY_SMH_0308_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0272/ses-2014-05-16-SMH0408_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0272/ses-2016-01-26-POPPY_SMH_0408_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0273/ses-2014-05-19-CWH0363_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0273/ses-2016-02-23-POPPY_CWH0363_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0276/ses-2014-05-21-SMH0411_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0276/ses-2016-05-31-POPPY_SMH0411_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0310/ses-2014-06-16-SMH0001_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0310/ses-2016-05-04-SMH0001_v2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0314/ses-2014-06-17-SMH0487_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0314/ses-2016-04-26-POPPY_SMH0487_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0319/ses-2014-06-25-SMH0424v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0319/ses-2014-07-11-SMH0424_v2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0319/ses-2016-02-23-POPPY_SMH0424_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0329/ses-2014-07-02-SMH0417_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0329/ses-2016-03-01-POPPY_SMH0417_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0401/ses-2014-08-26-CWH0602_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0401/ses-2016-02-26-POPPY_CWH0602_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0439/ses-2014-09-16-CWH0485V1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0439/ses-2016-02-10-POPPY_CWH0485_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0471/ses-2014-10-03-CWH0631_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0471/ses-2016-02-19-POPPY_CWH0631_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0476/ses-2014-10-06-CWH0632_v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0476/ses-2016-02-19-POPPY_CWH0632_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0481/ses-2014-10-07-SMH0627v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0481/ses-2016-02-12-POPPY_SMH0627_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0487/ses-2014-10-14-SMH0687v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0487/ses-2016-03-15-POPPY_SMH0687_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0491/ses-2014-10-15-SMH0701v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0491/ses-2016-04-05-POPPY_SMH0701_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0529/ses-2014-10-28-UCL0349v1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0529/ses-2016-04-01-POPPY_UCL0349_V2/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0879/ses-DREAM035_baseline_1/anat/T1w/smwc1*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0092/ses-2013-10-28-13_10_28_visit1_SMH0076/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0092/ses-2015-10-27-POPPY_SMH0076/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0117/ses-2013-11-29-13_11_29_visit1_SMH0070/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0117/ses-2015-10-13-POPPY_SMH0070_MV2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0135/ses-2013-12-20-13_12_20_visit1_SMH0193/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0135/ses-2015-10-30-POPPY_SMH0193_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0148/ses-2014-01-21-14_01_21_visit1_SMH0228v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0148/ses-2015-11-11-POPPY_SMH0228_MV2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0150/ses-2014-01-28-14_01_28_visit1_SMH0213v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0150/ses-2015-11-03-POPPY_SMH0213_MV2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0157/ses-2014-02-03-14_02_03_visit1_SMH0206v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0157/ses-2015-11-30-POPPY_SMH_0206_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0202/ses-2014-03-07-14_03_07_visit1_SMH0299v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0202/ses-2015-12-08-POPPY_SMH_0299_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0203/ses-2014-03-07-14_03_07_visit1_SMH0286v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0203/ses-2015-12-08-SMH_0286_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0215/ses-2014-03-13-14_03_13_visit1_SMH0313v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0215/ses-2015-12-01-POPPY_SMH0313_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0217/ses-2014-03-14-14_03_14_visit1_SMH0323v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0217/ses-2015-12-08-POPPY_SMH0323_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0220/ses-2014-03-24-14_03_24_visit1_SMH0301v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0220/ses-2015-11-17-POPPY_SMH0301_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0225/ses-2014-03-27-14_03_27_visit1_SMH0334v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0225/ses-2015-09-14-SMH0334_MV2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0237/ses-2014-04-10-SMH0308_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0237/ses-2016-02-09-POPPY_SMH_0308_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0272/ses-2014-05-16-SMH0408_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0272/ses-2016-01-26-POPPY_SMH_0408_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0273/ses-2014-05-19-CWH0363_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0273/ses-2016-02-23-POPPY_CWH0363_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0276/ses-2014-05-21-SMH0411_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0276/ses-2016-05-31-POPPY_SMH0411_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0310/ses-2014-06-16-SMH0001_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0310/ses-2016-05-04-SMH0001_v2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0314/ses-2014-06-17-SMH0487_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0314/ses-2016-04-26-POPPY_SMH0487_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0319/ses-2014-06-25-SMH0424v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0319/ses-2014-07-11-SMH0424_v2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0319/ses-2016-02-23-POPPY_SMH0424_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0329/ses-2014-07-02-SMH0417_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0329/ses-2016-03-01-POPPY_SMH0417_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0401/ses-2014-08-26-CWH0602_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0401/ses-2016-02-26-POPPY_CWH0602_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0439/ses-2014-09-16-CWH0485V1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0439/ses-2016-02-10-POPPY_CWH0485_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0471/ses-2014-10-03-CWH0631_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0471/ses-2016-02-19-POPPY_CWH0631_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0476/ses-2014-10-06-CWH0632_v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0476/ses-2016-02-19-POPPY_CWH0632_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0481/ses-2014-10-07-SMH0627v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0481/ses-2016-02-12-POPPY_SMH0627_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0487/ses-2014-10-14-SMH0687v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0487/ses-2016-03-15-POPPY_SMH0687_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0491/ses-2014-10-15-SMH0701v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0491/ses-2016-04-05-POPPY_SMH0701_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0529/ses-2014-10-28-UCL0349v1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0529/ses-2016-04-01-POPPY_UCL0349_V2/anat/T1w/smwc2*_T1w.nii: No such file or directory\n",
      "ls: /Users/nbourke/hpc/eph/ssbv/data/sub-CIF0879/ses-DREAM035_baseline_1/anat/T1w/smwc2*_T1w.nii: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "${fsl}\n",
    "#----------------\n",
    "\n",
    "dataDir=${workingDir}/volumetric_results\n",
    "cdir=${wd}/volumetric_results\n",
    "mkdir -p ${dataDir}/tractStats\n",
    "tractDIR=~/hpc/templates/Corrected_Tracts_MNI1mm/\n",
    "\n",
    "# List standard GM\n",
    "echo \"\" > ${workingDir}/smwc1_list.txt\n",
    "\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "        FILE=`ls ${workingDir}/data/${subject}/${ses}/anat/T1w/smwc1*_T1w.nii`  \n",
    "        if [ -f \"$FILE\" ]; then\n",
    "          echo \"${wd}\"/data/${subject}/${ses}/anat/T1w/smwc1${subject}_${ses}_T1w.nii >> ${workingDir}/smwc1_list.txt\n",
    "        fi\n",
    "    done\n",
    "done\n",
    "    \n",
    "\n",
    "# list standard WM\n",
    "echo \"\" > ${workingDir}/smwc2_list.txt\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "        FILE=`ls ${workingDir}/data/${subject}/${ses}/anat/T1w/smwc2*_T1w.nii`  \n",
    "        if [ -f \"$FILE\" ]; then\n",
    "          echo \"${wd}\"/data/${subject}/${ses}/anat/T1w/smwc2${subject}_${ses}_T1w.nii >> ${workingDir}/smwc2_list.txt\n",
    "        fi\n",
    "    done\n",
    "done\n",
    "    \n",
    "echo \"\" > ./tmp/smwc1statsJob.txt;\n",
    "job1=./tmp/smwc1statsJob.txt;\n",
    "\n",
    "echo \"\" > ./tmp/smwc2statsJob.txt;\n",
    "job2=./tmp/smwc2statsJob.txt;\n",
    "    \n",
    "echo \"module load fsl; fslmerge -t ${cdir}/all_smwc1 \\`cat ${wd}/smwc1_list.txt\\`; fslmaths ${cdir}/all_smwc1 -max 0 -Tmin -bin ${cdir}/all_smwc1_mask -odt char; fslmaths ${cdir}/all_smwc1 -mas ${cdir}/all_smwc1_mask ${cdir}/all_smwc1; fslmaths ${cdir}/all_smwc1 -Tmean ${cdir}/mean_smwc1; fslmaths ${cdir}/mean_smwc1 -thr 0.5 -bin ${cdir}/mean_smwc1_mask \" > ${job1}\n",
    "echo \"module load fsl; fslmerge -t ${cdir}/all_smwc2 \\`cat ${wd}/smwc2_list.txt\\`; fslmaths ${cdir}/all_smwc2 -max 0 -Tmin -bin ${cdir}/all_smwc2_mask -odt char; fslmaths ${cdir}/all_smwc2 -mas ${cdir}/all_smwc2_mask ${cdir}/all_smwc2; fslmaths ${cdir}/all_smwc2 -Tmean ${cdir}/mean_smwc2; fslmaths ${cdir}/mean_smwc2 -thr 0.5 -bin ${cdir}/mean_smwc2_mask \" > ${job2} \n",
    "\n",
    "# # create mean GM\n",
    "# fslmaths ${dataDir}/all_smwc1 -max 0 -Tmin -bin ${dataDir}/all_smwc1_mask -odt char\n",
    "# fslmaths ${dataDir}/all_smwc1 -mas ${dataDir}/all_smwc1_mask ${dataDir}/all_smwc1\n",
    "# fslmaths ${dataDir}/all_smwc1 -Tmean ${dataDir}/mean_smwc1\n",
    "# fslmaths ${dataDir}/mean_smwc1 -thr 0.5 -bin ${dataDir}/mean_smwc1_mask \n",
    "\n",
    "# # create mean WM\n",
    "# fslmaths ${dataDir}/all_smwc2 -max 0 -Tmin -bin ${dataDir}/all_smwc2_mask -odt char\n",
    "# fslmaths ${dataDir}/all_smwc2 -mas ${dataDir}/all_smwc2_mask ${dataDir}/all_smwc2\n",
    "# fslmaths ${dataDir}/all_smwc2 -Tmean ${dataDir}/mean_smwc2\n",
    "# fslmaths ${dataDir}/mean_smwc2 -thr 0.5 -bin ${dataDir}/mean_smwc2_mask \n",
    "\n",
    "    # Run job\n",
    "    ~/hpc/repos/ssbv/lib/localSubmit ${job1} 48:00:00 3 16Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"; head ${job1}  \n",
    "    \n",
    "        # Run job\n",
    "    ~/hpc/repos/ssbv/lib/localSubmit ${job2} 48:00:00 3 16Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"; head ${job2}  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "${fsl}\n",
    "#----------------\n",
    "\n",
    "dataDir=${workingDir}/volumetric_results\n",
    "cdir=${wd}/volumetric_results\n",
    "mkdir -p ${dataDir}/tractStats\n",
    "tractDIR=~/hpc/templates/Corrected_Tracts_MNI1mm/\n",
    "\n",
    "#Find the tract masks\n",
    "cd ${tractDIR}\n",
    "TRACTS=`ls *.gz`\n",
    "\n",
    "# Nested for loop - for each mask and each metric do fslstats\n",
    "for i in $TRACTS; \n",
    "do\n",
    "    #j=$(echo ${i} | cut -d '_' -f2-)\n",
    "    k=$(echo ${i} | cut -d '.' -f1)\n",
    "    \n",
    "    echo $k > ${dataDir}/tractStats/vol_MNI_${k}.txt\n",
    "    fslstats -t ${dataDir}/all_smwc2.nii.gz -k ${tractDIR}/$i -M >> ${dataDir}/tractStats/vol_MNI_${k}.txt\n",
    "done \n",
    "\n",
    "cp ${workingDir}/smwc2_list.txt ${dataDir}/tractStats/aaa.txt\n",
    "\n",
    "echo \"WM_VOL\" > ${dataDir}/tractStats/vol_MNI_WM.txt\n",
    "fslstats -t ${dataDir}/all_smwc2.nii.gz -k ${dataDir}/mean_smwc2_mask.nii.gz -M >> ${dataDir}/tractStats/vol_MNI_WM.txt \n",
    "echo \"GM_VOL\" > ${dataDir}/tractStats/vol_MNI_GM.txt\n",
    "fslstats -t ${dataDir}/all_smwc1.nii.gz -k ${dataDir}/mean_smwc1_mask.nii.gz -M >> ${dataDir}/tractStats/vol_MNI_GM.txt\n",
    "\n",
    "\n",
    "# paste -d , `ls` >> ../tractStats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grey matter ROIs (Harvard-Oxford atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "\n",
    "workingDir=/Users/nbourke/hpc/eph/ssbv/\n",
    "#------------------\n",
    "\n",
    "\n",
    "# set output dir\n",
    "dataDir=${workingDir}/volumetric_results\n",
    "mkdir -p ${dataDir}/roiStats\n",
    "\n",
    "# source atlas\n",
    "atlasDIR=~/hpc/templates/HarvardOxford-atlas/\n",
    "\n",
    "# set job\n",
    "for brain in cortical subcortical; \n",
    "    do\n",
    "    cd ${atlasDIR}/${brain}/masks/\n",
    "    ROI=`ls *nii.gz`\n",
    "\n",
    "    # Nested for loop - for each mask and each metric do fslstats\n",
    "    for i in ${ROI}; \n",
    "        do\n",
    "        k=$(echo ${i} | cut -d '.' -f1); \n",
    "        echo $k > ${dataDir}/roiStats/vol_MNI_${k}.txt;\n",
    "        #echo \"fslstats -t ${dataDir}/all_smwc1.nii.gz -k ${atlasDIR}/${brain}/masks/${i} -M -V | awk {'print \\$1 * \\$3'} >> ${dataDir}/roiStats/vol_MNI_${k}.txt\" >> ${job}  \n",
    "        fslstats -t ${dataDir}/all_smwc1.nii.gz -k ${atlasDIR}/${brain}/masks/${i} -M >> ${dataDir}/roiStats/MI_MNI_${k}.txt\n",
    "    done\n",
    "done \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Remember to copy relevent outputs to derivitives! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "${fsl}\n",
    "#----------------\n",
    "\n",
    "dataDir=${workingDir}/volumetric_results\n",
    "mkdir -p ${dataDir}/tractStats\n",
    "tractDIR=~/templates/Corrected_Tracts/\n",
    "\n",
    "\n",
    "#Find the tract masks\n",
    "cd ${tractDIR}\n",
    "TRACTS=`ls *.gz`\n",
    "\n",
    "# Nested for loop - for each mask and each metric do fslstats\n",
    "for i in $TRACTS; \n",
    "do\n",
    "    #j=$(echo ${i} | cut -d '_' -f2-)\n",
    "    k=$(echo ${i} | cut -d '.' -f1)\n",
    "    \n",
    "    echo $k > ${dataDir}/tractStats/vol_MNI_${k}.txt\n",
    "    fslstats -t ${dataDir}/all_smwc2.nii.gz -k ${tractDIR}/$i -M >> ${dataDir}/tractStats/vol_MNI_${k}.txt\n",
    "done \n",
    "\n",
    "cp ${workingDir}/smwc2_list.txt ${dataDir}/tractStats/aaa.txt\n",
    "\n",
    "\n",
    "# paste -d , `ls` >> ../tractStats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelwise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "${fsl}\n",
    "#----------------\n",
    "\n",
    "# Update working dir, as done after main analysis was conducted\n",
    "wd=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds\n",
    "\n",
    "# Remove pilot\n",
    "fslmerge -t ${wd}/derivatives/volumetric_results/all_smwc1 `cat ${wd}/derivatives/volumetric_results/smwc1_list.txt`\n",
    "fslmerge -t ${wd}/derivatives/volumetric_results/all_smwc2 `cat ${wd}/derivatives/volumetric_results/smwc2_list.txt`\n",
    "\n",
    "# design=${scriptDir}/scripts/design/demo.mat\n",
    "# contrast=${scriptDir}/scripts/design/mainContrast.con \n",
    "# setup_masks ${design} ${contrast} ${scriptDir}/scripts/design/${ii} `cat ${scriptDir}/scripts/design/masks.txt` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "module load fsl/6.0.1/\n",
    "#----------------------------\n",
    "\n",
    "wd=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds\n",
    "design=${wd}/scripts/design/demo.mat\n",
    "contrast=${wd}/scripts/design/mainContrast.con\n",
    "\n",
    "# Run setup masks command\n",
    "setup_masks ${design} ${contrast} ${wd}/scripts/design/MNIlesion `ls ${wd}/derivatives/lesionMasks/MNI/bin*`   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "module load fsl/6.0.1/\n",
    "#----------------------------\n",
    "\n",
    "# Update working dir, as done after main analysis was conducted\n",
    "wd=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds\n",
    "output=${wd}/tbss_lesion_output/\n",
    "\n",
    "# Remove pilot\n",
    "# fslmerge -t ${wd}/derivatives/volumetric_results/all_smwc1 `cat ${wd}/derivatives/volumetric_results/smwc1_list.txt`\n",
    "# fslmerge -t ${wd}/derivatives/volumetric_results/all_smwc2 `cat ${wd}/derivatives/volumetric_results/smwc2_list.txt`\n",
    "\n",
    "for ii in smwc1 smwc2\n",
    "    do\n",
    "    data_input=${wd}/derivatives/volumetric_results/all_${ii}.nii.gz\n",
    "    data_mask=${wd}/derivatives/volumetric_results/mean_${ii}_mask.nii.gz\n",
    "    design=${wd}/scripts/design/MNIlesion.mat\n",
    "    contrast=${wd}/scripts/design/MNIlesion.con\n",
    "    basename=${wd}/scripts/design/MNIlesion.nii.gz\n",
    "    \n",
    "    mkdir ${output}/${ii}\n",
    "    ## Run command ##\n",
    "    ${dep}/pbs_randomise_par -wt 24:00:00 -mem 14Gb -i ${data_input} -o ${output}/${ii}/${ii}_TBSS -m ${data_mask} -d ${design} -t ${contrast} --vxl=-4 --vxf=${basename} -n 5000 --T2 -V  \n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freesurfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "module load fsl\n",
    "#----------------------------\n",
    "\n",
    "# Set job command File \n",
    "echo -n \"\" > ${workingDir}/${project}_fs_job.txt\n",
    "job=${workingDir}/${project}_fs_job.txt\n",
    "\n",
    "\n",
    "### Job loop ###\n",
    "for subject in sub-CIF1703 sub-CIF2178 #`ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "        rm -r ${workingDir}/data/${subject}/${ses}/anat/T1w/fs\n",
    "        rm -r ${workingDir}/data/${subject}/${ses}/anat/T1w/fsaverage\n",
    "        rm -r ${workingDir}/data/${subject}/${ses}/anat/T1w/T1w\n",
    "        echo \"/rds/general/user/nbourke/home/group_paeds/scripts/pbsFreesurfer -i ${subject} ${ses} ${workingDir}\" >> ${job}           \n",
    "    done\n",
    "done\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 20:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *The following aparcstats2table command works when copied into the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "module load fsl\n",
    "module load freesurfer\n",
    "#----------------------------\n",
    "EXPERIMENT_DIR=${workingDir}\n",
    "export SUBJECTS_DIR=`${workingDir}/data/`\n",
    "\n",
    "\n",
    "counter=1\n",
    "### Job loop ###\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do  \n",
    "        echo -e \"$( if [ \"${counter}\" -eq \"1\" ]; then echo \"First run: \"; fi )${subject}\"\n",
    "\n",
    "        \n",
    "        XX=${workingDir}/data/${subject}/${ses}/anat/T1w/fs \n",
    "        #Thickness\n",
    "        aparcstats2table --subjects $XX --hemi rh --meas thickness  --tablefile ${workingDir}/data/${subject}/${ses}/anat/T1w/fs/rh_thick_aparc_stats.txt\n",
    "        aparcstats2table --subjects $XX --hemi lh --meas thickness  --tablefile ${workingDir}/data/${subject}/${ses}/anat/T1w/fs/lh_thick_aparc_stats.txt\n",
    "        # Volume\n",
    "        aparcstats2table --subjects $XX --hemi rh --meas volume --tablefile ${workingDir}/data/${subject}/${ses}/anat/T1w/fs/rh_vol_aparc_stats.txt\n",
    "        aparcstats2table --subjects $XX --hemi lh --meas volume --tablefile ${workingDir}/data/${subject}/${ses}/anat/T1w/fs/lh_vol_aparc_stats.txt\n",
    "        \n",
    "        \n",
    "    done\n",
    "    counter=$((counter +1))\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting FreeSurfer measurments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "echo \"\" > ${workingDir}/rh_thick_aparc_stats.txt\n",
    "echo \"\" > ${workingDir}/lh_thick_aparc_stats.txt\n",
    "echo \"\" > ${workingDir}/rh_vol_aparc_stats.txt\n",
    "echo \"\" > ${workingDir}/lh_vol_aparc_stats.txt\n",
    "\n",
    "counter=1\n",
    "### Job loop ###\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do  \n",
    "        XX=${workingDir}/data/${subject}/${ses}/anat/T1w/fs\n",
    "        \n",
    "        echo -e \"$( if [ \"${counter}\" -eq \"10\" ]; then sed '1q;d' ${XX}/rh_thick_aparc_stats.txt >> ${workingDir}/rh_thick_aparc_stats.txt; sed '1q;d' ${XX}/lh_thick_aparc_stats.txt >> ${workingDir}/lh_thick_aparc_stats.txt; sed '1q;d' ${XX}/rh_vol_aparc_stats.txt >> ${workingDir}/rh_vol_aparc_stats.txt; sed '1q;d' ${XX}/lh_vol_aparc_stats.txt >> ${workingDir}/lh_vol_aparc_stats.txt; fi )\"  \n",
    " \n",
    "        sed '2q;d' ${XX}/rh_thick_aparc_stats.txt >> ${workingDir}/rh_thick_aparc_stats.txt\n",
    "        sed '2q;d' ${XX}/lh_thick_aparc_stats.txt >> ${workingDir}/lh_thick_aparc_stats.txt\n",
    "        sed '2q;d' ${XX}/rh_vol_aparc_stats.txt >> ${workingDir}/rh_vol_aparc_stats.txt\n",
    "        sed '2q;d' ${XX}/lh_vol_aparc_stats.txt >> ${workingDir}/lh_vol_aparc_stats.txt\n",
    "\n",
    "    done\n",
    "    counter=$((counter +1))\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. mv to local\n",
    "2. open in excell\n",
    "3. correct heading\n",
    "4. save as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering lesion masks to MNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "echo \"\" > ${workingDir}/commandLogs/lesion_reg.txt\n",
    "job=${workingDir}/commandLogs/lesion_reg.txt\n",
    "mkdir ${workingDir}/tmpReg\n",
    "### Job loop ###\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do  \n",
    "        brain=${workingDir}/data/${subject}/${ses}/anat/T1w/${subject}_${ses}_T1w_brain.nii.gz  \n",
    "        lesion=${workingDir}/lesionMasks/${subject}_${ses}_contusion.nii.gz\n",
    "        \n",
    "        if [ -f \"$lesion\" ]; then\n",
    "            echo \"$ses has a lesion\"\n",
    "            echo \"${fsl}; flirt -in ${brain} -ref /rds/general/apps/fsl/5.0.10/install/data/standard/MNI152_T1_1mm_brain.nii.gz -omat ${workingDir}/tmpReg/${subject}_${ses}_T1brain2MNI.mat -dof 6 -cost mutualinfo -searchcost mutualinfo; flirt -in ${lesion} -ref /rds/general/apps/fsl/5.0.10/install/data/standard/MNI152_T1_1mm_brain.nii.gz -applyxfm -init ${workingDir}/tmpReg/${subject}_${ses}_T1brain2MNI.mat -out ${workingDir}/lesionMasks/MNI/${subject}_${ses}_contusion_MNI.nii.gz\" >> ${job}  \n",
    "        else\n",
    "            echo \"$ses does not have a lesion, making empty mask file\"\n",
    "            cp /rds/general/user/nbourke/home/templates/MNI152_T1_1mm_empty_mask.nii ${workingDir}/lesionMasks/MNI/${subject}_${ses}_empty_mask_MNI.nii.gz\n",
    "        fi\n",
    "    done\n",
    "done\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 08:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
